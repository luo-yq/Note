
study
oracle锁

    所谓的锁机制是用于共享资源的并发访问。在单用户数据库中，并不需要锁。如果有多个用户访问或修改数据或和数据结构，就需要一种机制来防止对同一信息的并发修改，这就是锁的用处。
    Oracle数据库的锁机制和别的都不同（可以说每种数据库本质上都有不同），在Oracle中，有几点要注意：
    1).事务是每个数据库的核心，它们是“好东西”。
    2).应该延迟到适当的时刻才提交。不要太快提交，以避免对系统带来压力。这是因为，如果事务很长或很大，一般不会对系统有压力。相应的原则是：在必要时才提交，但是此前不要提交。事务的大小只应该根据业务逻辑来定。
    3).只要需要，就应该尽可能长时间地保持对数据所加的锁。这些锁是你能利用的工具，而不是让你退避三舍的东西。锁不是稀有资源。恰恰相反，只要需要，你就应该长期地保持数据上的锁。锁可能并不稀少，而且它们可以防止其他会话修改信息。
    4).在Oracle中，行级锁没有相关的开销，根本没有。不论你是有1个行锁，还是1 000 000个行锁，专用于锁定这个信息的“资源”数都是一样的。当然，与修改1行相比，修改1 000 000行要做的工作肯定多得多，但是对1 000 000行锁定所需的资源数与对1行锁定所需的资源数完全相同，这是一个固定的常量。
    5).不要以为锁升级“对系统更好”（例如，使用表锁而不是行锁）。在Oracle中，锁升级（lock escalate）对系统没有任何好处，不会节省任何资源。也许有时会使用表锁，如批处理中，此时你很清楚会更新整个表，而且不希望其他会话锁定表中的行。但是使用表锁绝对不是为了避免分配行锁，想以此来方便系统。
    6).可以同时得到并发性和一致性。每次你都能快速而准确地得到数据。数据读取器不会被数据写入器阻塞。数据写入器也不会被数据读取器阻塞。这是 Oracle与大多数其他关系数据库之间的根本区别之一。
    锁定问题有：丢失更新。处理的办法有两种：
1.悲观锁定
    这种锁定机制就是用户一开始修改某行时，就立刻放上一个行锁。悲观锁定（pessimistic locking）仅用于有状态（stateful）或有连接（connected）环境，也就是说，你的应用与数据库有一条连续的连接，而且至少在事务生存期中只有你一个人使用这条连接。这是20世纪90年代中期客户/服务器应用中的一种流行做法。每个应用都得到数据库的一条直接连接，这条连接只能由该应用实例使用。这种采用有状态方式的连接方法已经不太常见了（不过并没有完全消失），特别是随着20世纪90年代中后期应用服务器的出现，有状态连接更是少见。
     这种锁定很悲观，因为我们不能对该行能否未改变持怀疑态度。
2.乐观锁定
     这种锁定机制是把所有锁定都延迟到即将执行更新才做。在修改信息时不会上锁，我们很乐观，认为数据不会被其他用户修改；因此，会等到最后一刻才去看我们的想法对不对。当他在更新的时候，发现数据被修改了，就得重新再来。
      实现乐观锁定有很多方法，一下简单介绍三种：
      a) 使用版本列的乐观锁定
      这是一个简单的实现，如果你想保护数据库表不出现丢失更新问题，应对每个要保护的表增加一列。这一列一般是NUMBER或DATE/TIMESTAMP 列，通常通过表上的一个行触发器来维护。每次修改行时，这个触发器要负责递增NUMBER列中的值，或者更新DATE/TIMESTAMP列。但是触发器会引入大量开销，建议还是不使用这种办法。
      b) 使用校验和的乐观锁定
      这与前面的版本列方法很相似，不过在此要使用基数据本身来计算一个“虚拟的”版本列。与使用版本列的做法一样，我们可以采用同样的方法使用这些散列值或校验和，只需把从数据库读出数据时得到的散列或校验和值与修改数据前得到的散列或校验和值进行比较。在我们读出数据之后，但是在修改数据之前，如果有人在这段时间内修改了这一行的值，散列值或校验和值往往会大不相同。
      c) 使用 ORA_ROWSCN的乐观锁定
      从Oracle 10g Release 1开始，你还可以使用内置的ORA_ROWSCN函数。它的工作与前面所述的版本列技术很相似，但是可以由Oracle自动执行，而不需要在表中增加额外的列，也不需要额外的更新/维护代码来更新这个值。
      ORA_ROWSCN建立在内部Oracle系统时钟（SCN）基础上。在Oracle中，每次提交时，SCN都会推进（其他情况也可能导致SCN推进，要注意，SCN只会推进，绝对不会后退）
      但是有个地方要注意，Oracle在默认情况下会采用块级推进ORA_ROWSCN，也就是说在一个块内多行会共享相同的ORA_ROWSCN，如果更新一个块上的某一行，而且这个块上还有另外50行，那么这些行的ORA_ROWSCN也会推进。这往往会导致许多假警报，你认为某一行已经修改，但实际上它并没有改动。因此，需要注意这一点，并了解如何改变这种行为。
       要改变这种默认的行为，我们必须启用ROWDEPENDENCIES再重新创建这个段。可以使用DBMS_REDEFINITION中（Oracle提供的另一个包）的在线重建功能来执行，但是对于小表可以直接删掉再重建。一个例子是：
       ops$tkyte@ORA10G> create table dept
             (deptno, dname, loc, data,
              constraint dept_pk primary key(deptno)
             )
            ROWDEPENDENCIES
            as
            select deptno, dname, loc, rpad('*',3500,'*')
            from scott.dept;
（二）阻塞
        如果一个会话持有某个资源的锁，而另一个会话在请求这个资源，就会出现阻塞（blocking）。这样一来，请求的会话会被阻塞，它会“挂起”，直至持有锁的会话放弃锁定的资源。几乎在所有情况下，阻塞都是可以避免的。
        数据库中有5条常见的DML语句可能会阻塞，具体是：INSERT、UPDATE、DELETE、MERGE和SELECT FOR UPDATE。对于一个阻塞的SELECT FOR UPDATE，解决方案很简单：只需增加NOWAIT子句，它就不会阻塞了。
 a) Insert 阻塞
        INSERT阻塞的情况不多见。最常见的情况是，你有一个带主键的表，或者表上有惟一的约束，但有两个会话试图用同样的值插入一行。如果是这样，其中一个会话就会阻塞，直到另一个会话提交或者回滚为止：如果另一个会话提交，那么阻塞的会话会收到一个错误，指出存在一个重复值；倘若另一个会话回滚，在这种情况下，阻塞的会话则会成功。还有一种情况，可能多个表通过引用完整性约束相互链接。对子表的插入可能会阻塞，因为它所依赖的父表正在创建或删除。
b) 阻塞的Merge、Update和Delete
 
       在一个交互式应用中，可以从数据库查询某个数据，允许最终用户处理这个数据，再把它“放回”到数据库中，此时如果UPDATE或DELETE阻塞，就说明你的代码中可能存在一个丢失更新问题（如果真是这样，按我的说法，就是你的代码中存在bug）。你试图UPDATE（更新）其他人正在更新的行（换句话说，有人已经锁住了这一行）。通过使用SELECT FOR UPDATE NOWAIT查询可以避免这个问题
(三) 死锁
      如果你有两个会话，每个会话都持有另一个会话想要的资源，此时就会出现死锁（deadlock）。例如，如果我的数据库中有两个表A和B，每个表中都只有一行，就可以很容易地展示什么是死锁。我要做的只是打开两个会话（例如，两个SQL*Plus会话）。在会话A中更新表A，并在会话B中更新表B。现在，如果我想在会话B中更新表A，就会阻塞。会话A已经锁定了这一行。这不是死锁；只是阻塞而已。我还没有遇到过死锁，因为会话A还有机会提交或回滚，这样会话B就能继续。如果我再回到会话A，试图更新表B，这就会导致一个死锁。要在这两个会话中选择一个作为“牺牲品”，让它的语句回滚。
      根据我的经验，导致死锁的头号原因是外键未加索引（这是因为加了索引后，删除父表记录后就不需要对子表加表级锁）例如：
      a) 如果更新了父表的主键（倘若遵循关系数据库的原则，即主键应当是不可变的，这种情况就很少见），由于外键上没有索引，所以子表会被锁住。
      b) 如果删除了父表中的一行，整个子表也会被锁住（由于外键上没有索引）。
      第二种情况比较常见，因为在删除父表的一行时，那么在DML操作期间，子表会被锁定，这样能避免事务期间对子表执行其他更新，但确实有人在修改子表时，删除则会等待。只有在外键加了索引后，才不会对子表加表级锁（这是为什么呢？）
(四) 锁类型
     Oracle中主要有3类锁，具体是：
a).DML锁（DML lock）：DML代表数据操纵语言（Data Manipulation Language）。一般来讲，这表示SELECT、INSERT、UPDATE、MERGE和DELETE语句。DML锁机制允许并发执行数据修改。例如，DML锁可能是特定数据行上的锁，或者是锁定表中所有行的表级锁。
b).DDL锁（DDL lock）：DDL代表数据定义语言（Data Definition Language），如CREATE和ALTER语句等。DDL锁可以保护对象结构
c).内部锁和闩：Oracle使用这些锁来保护其内部数据结构。例如，Oracle解析一个查询并生成优化的查询计划时，它会把库缓存“临时闩”，将计划放在那里，以供其他会话使用。闩（latch）是Oracle采用的一种轻量级的低级串行化设备，功能上类似于锁。不要被“轻量级”这个词搞糊涂或蒙骗了，你会看到，闩是数据库中导致竞争的一个常见原因。轻量级指的是闩的实现，而不是闩的作用
DML锁的有：
1) TX锁（事务锁）
     事务发起第一个修改时会得到TX锁（事务锁），而且会一直持有这个锁，直至事务执行提交（COMMIT）或回滚（ROLLBACK）。TX锁用作一种排队机制，使得其他会话可以等待这个事务执行。Oracle并 没有一个传统的锁管理器，不会用锁管理器为系统中锁定的每一行维护一个长长的列表。不过，其他的许多数据库却是这样做的，因为对于这些数据库来说，锁是一 种稀有资源，需要对锁的使用进行监视。使用的锁越多，系统要管理的方面就越多，所以在这些系统中，如果使用了“太多的”锁就会有问题。
      如果数据库中有一个传统的基于内存的锁管理器，在这样一个数据库中，对一行锁定的过程一般如下：
  (1) 找到想锁定的那一行的地址。
  (2) 在锁管理器中排队（锁管理器必须是串行化的，因为这是一个常见的内存中的结构）。
  (3) 锁定列表。
  (4) 搜索列表，查看别人是否已经锁定了这一行。
  (5) 在列表中创建一个新的条目，表明你已经锁定了这一行。
  (6) 对列表解锁。
  既然已经锁定了这一行，接下来就可以修改它了。之后，在你提交修改时，必须继续这个过程，如下：
  (7) 再次排队。
  (8) 锁住锁的列表。
  (9) 在这个列表中搜索，并释放所有的锁。
  (10) 对列表解锁。
  Oracle不是这样做的。Oracle中的锁定过程如下：
  (1) 找到想锁定的那一行的地址。
  (2) 到达那一行。
  (3) 锁定这一行（如果这一行已经锁定，则等待锁住它的事务结束，除非使用了NOWAIT选项）
2)TM (DML Enqueue)锁
    TM锁（TM lock）用于确保在修改表的内容时，表的结构不会改变。例如，如果你已经更新了一个表，会得到这个表的一个TM锁。这会防止另一个用户在该表上执行DROP或ALTER命令。
     尽管每个事务只能得到一个TX锁，但是TM锁则不同，修改了多少个对象，就能得到多少个TM锁。在此，有意思的是，TM锁的ID1列就是DML锁定对象的对象ID，所以，很容易发现哪个对象持有这个锁。
     这个锁主要用于保护数据，和DDL锁有不同的地方。
DDL锁有：
    在DDL操作中会自动为对象加DDL锁（DDL Lock），从而保护这些对象不会被其他会话所修改。例如，如果我执行一个DDL操作ALTERTABLE T，表T上就会加一个排他DDL锁，以防止其他会话得到这个表的DDL锁和TM锁。在DDL语句执行期间会一直持有DDL锁，一旦操作执行就立即释放DDL锁。实际上，通常会把DDL语句包装在隐式提交（或提交/回滚对）中来执行这些工作。由于这个原因，在Oracle中DDL一定会提交。
    因此，DDL总会提交（即使提交不成功也会如此）。DDL一开始就提交，一定要知道这一点。它首先提交，因此如果必须回滚，它不会回滚你的事务。如果你执行了DDL，它会使你所执行的所有未执行的工作成为永久性的，即使DDL不成功也会如此。如果你需要执行DDL，但是不想让它提交你现有的事务，就可以使用一个自治事务（autonomous transaction）。
     有3种类型的DDL锁：
1）排他DDL锁（Exclusive DDL lock）：这会防止其他会话得到它们自己的DDL锁或TM（DML）锁。这说明，在DDL操作期间你可以查询一个表，但是无法以任何方式修改这个表。
2）共享DDL锁（Share DDL lock）：这些锁会保护所引用对象的结构，使之不会被其他会话修改，但是允许修改数据。
3) 可中断解析锁（Breakable parse locks）：这些锁允许一个对象（如共享池中缓存的一个查询计划）向另外某个对象注册其依赖性。如果在被依赖的对象上执行DDL，Oracle会查看已经对该对象注册了依赖性的对象列表，并使这些对象无效。因此，这些锁是“可中断的”，它们不能防止DDL出现。
      最后看看闩，闩（latch）是轻量级的串行化设备，用于协调对共享数据结构、对象和文件的多用户访问。
      闩就是一种锁，设计为只保持极短的一段时间（例如，修改一个内存中数据结构所需的时间）。闩用于保护某些内存结构，如数据库块缓冲区缓存或共享池中的库缓存。
      这表明闩是专门用于保护Oracle内部的数据结构的，锁是用于保护数据表等用户的共享资源。
      还有闩的自旋的一些概念这里就不提了。
Oracle的悲观锁和乐观锁
为了得到最大的性能，一般数据库都有并发机制，不过带来的问题就是数据访问的冲突。为了解决这个问题，大多数数据库用的方法就是数据的锁定。
数据的锁定分为两种方法，第一种叫做悲观锁，第二种叫做乐观锁。什么叫悲观锁呢，悲观锁顾名思义，就是对数据的冲突采取一种悲观的态度，也就是说假设数据肯定会冲突，所以在数据开始读取的时候就把数据锁定住。而乐观锁就是认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让用户返回错误的信息，让用户决定如何去做。
先从悲观锁开始说。在SqlServer等其余很多数据库中，数据的锁定通常采用页级锁的方式，也就是说对一张表内的数据是一种串行化的更新插入机制，在任何时间同一张表只会插1条数据，别的想插入的数据要等到这一条数据插完以后才能依次插入。带来的后果就是性能的降低，在多用户并发访问的时候，当对一张表进行频繁操作时，会发现响应效率很低，数据库经常处于一种假死状态。而Oracle用的是行级锁，只是对想锁定的数据才进行锁定，其余的数据不相干，所以在对Oracle表中并发插数据的时候，基本上不会有任何影响。
注：对于悲观锁是针对并发的可能性比较大，而一般在我们的应用中用乐观锁足以。
Oracle的悲观锁需要利用一条现有的连接，分成两种方式，从SQL语句的区别来看，就是一种是for update，一种是for update nowait的形式。比如我们看一个例子。首先建立测试用的数据库表。
CREATE TABLE TEST(ID,NAME,LOCATION,VALUE,CONSTRAINT test_pk PRIMARY KEY(ID))AS SELECT deptno, dname, loc, 1 FROM scott.dept
这里我们利用了Oracle的Sample的scott用户的表，把数据copy到我们的test表中。首先我们看一下for update锁定方式。首先我们执行如下的select for update语句。
select * from test where id = 10 for update
通过这条检索语句锁定以后，再开另外一个sql*plus窗口进行操作，再把上面这条sql语句执行一便，你会发现sqlplus好像死在那里了，好像检索不到数据的样子，但是也不返回任何结果，就属于卡在那里的感觉。这个时候是什么原因呢，就是一开始的第一个Session中的select for update语句把数据锁定住了。由于这里锁定的机制是wait的状态(只要不表示nowait那就是wait)，所以第二个Session(也就是卡住的那个sql*plus)中当前这个检索就处于等待状态。当第一个session最后commit或者rollback之后，第二个session中的检索结果就是自动跳出来，并且也把数据锁定住。不过如果你第二个session中你的检索语句如下所示。
select * from test where id = 10
也就是没有for update这种锁定数据的语句的话，就不会造成阻塞了。另外一种情况，就是当数据库数据被锁定的时候，也就是执行刚才for update那条sql以后，我们在另外一个session中执行for update nowait后又是什么样呢。比如如下的sql语句。 由于这条语句中是制定采用nowait方式来进行检索，所以当发现数据被别的session锁定中的时候，就会迅速返回ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源。所以在程序中我们可以采用nowait方式迅速判断当前数据是否被锁定中，如果锁定中的话，就要采取相应的业务措施进行处理。
select * from test where id = 10 for update nowait
那这里另外一个问题，就是当我们锁定住数据的时候，我们对数据进行更新和删除的话会是什么样呢。比如同样，我们让第一个Session锁定住id=10的那条数据，我们在第二个session中执行如下语句。
update test set value=2 where id = 10
这个时候我们发现update语句就好像select for update语句一样也停住卡在这里，当你第一个session放开锁定以后update才能正常运行。当你update运行后，数据又被你update语句锁定住了，这个时候只要你update后还没有commit，别的session照样不能对数据进行锁定更新等等。
总之，Oracle中的悲观锁就是利用Oracle的Connection对数据进行锁定。在Oracle中，用这种行级锁带来的性能损失是很小的，只是要注意程序逻辑，不要给你一不小心搞成死锁了就好。而且由于数据的及时锁定，在数据提交时候就不呼出现冲突，可以省去很多恼人的数据冲突处理。缺点就是你必须要始终有一条数据库连接，就是说在整个锁定到最后放开锁的过程中，你的数据库联接要始终保持住。与悲观锁相对的，我们有了乐观锁。乐观锁一开始也说了，就是一开始假设不会造成数据冲突，在最后提交的时候再进行数据冲突检测。在乐观锁中，我们有3种
常用的做法来实现。
[1]第一种就是在数据取得的时候把整个数据都copy到应用中，在进行提交的时候比对当前数据库中的数据和开始的时候更新前取得的数据。当发现两个数据一模一样以后，就表示没有冲突可以提交，否则则是并发冲突，需要去用业务逻辑进行解决。
[2]第二种乐观锁的做法就是采用版本戳，这个在Hibernate中得到了使用。采用版本戳的话，首先需要在你有乐观锁的数据库table上建立一个新的column，比如为number型，当你数据每更新一次的时候，版本数就会往上增加1。比如同样有2个session同样对某条数据进行操作。两者都取到当前的数据的版本号为1，当第一个session进行数据更新后，在提交的时候查看到当前数据的版本还为1，和自己一开始取到的版本相同。就正式提交，然后把版本号增加1，这个时候当前数据的版本为2。当第二个session也更新了数据提交的时候，发现数据库中版本为2，和一开始这个session取到的版本号不一致，就知道别人更新过此条数据，这个
时候再进行业务处理，比如整个Transaction都Rollback等等操作。在用版本戳的时候，可以在应用程序侧使用版本戳的验证，也可以在数据库侧采用Trigger(触发器)来进行验证。不过数据库的Trigger的性能开销还是比较的大，所以能在应用侧进行验证的话还是推荐不用Trigger。
[3]第三种做法和第二种做法有点类似，就是也新增一个Table的Column，不过这次这个column是采用timestamp型，存储数据最后更新的时间。在Oracle9i以后可以采用新的数据类型，也就是timestamp with time zone类型来做时间戳。这种Timestamp的数据精度在Oracle的时间类型中是最高的，精确到微秒(还没与到纳秒的级别)，一般来说，加上数据库处理时间和人的思考动作时间，微秒级别是非常非常够了，其实只要精确到毫秒甚至秒都应该没有什么问题。和刚才的版本戳类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。如果不想把代码写在程序中或者由于别的原因无法把代码写在现有的程序中，也可以把这个时间戳乐观锁逻辑写在Trigger或者存储过程中。
锁策略
为防止丢失更新，有两种锁策略：悲观锁定和乐观锁定

悲观锁定：
从数据库查询一行时，就锁定这一行，不允许其他会话更新，这种方法叫悲观锁定。在试图更新之前我们就把行锁定了，因为我们很悲观，对于这一行能不能保持未改变很怀疑。

乐观锁定：
把所有锁定都延迟到即将执行更新之前才做。我们很乐观，认为数据不会被其他用户修改。采用这种方法，执行更新的用户“失败”的可能性会加大。

实现乐观锁定的方法：
1）前影像方法:
   在应用中同时保留旧值和新值，在更新时通过判断列值等于旧值的方法判断是否更新。
2）使用版本列:
   对要保护的列增加一列。这个列一般是number或date/timestamp列，通常通过表上的一个行触发器来维护。每次修改行时，这个触发器要负责递增number列的值，或更新date/timestanp列。比如我们经常使用的version, last_upd_date列。
   应用之需要验证请求更新那一刻，数据库中的这一列的值与最初读出的值是否匹配。如果这两个值相等，就说明这一行被更新过。
3）使用校验和:
   采用计算散列值或校验和的方法，把从数据库读出数据时得到的散列值或校验和值与修改数据前得到的散列或校验和值进行比较。散列值就是一个很大的16进制位串。计算散列或校验和值是一个CPU密集型操作（相当占用CPU），其计算代价很昂贵。它的优点是只需在网络上传输相当小的散列值，而不是行的完整的前影像和后影像，所以消耗的资源少得多。
4）使用ora_rowscn:

   ora_rowscn不是表的一个列，可以看做是块的标记，它由Oracle自动执行，而不需要在表中增加额外的列，也不需要额外的更新/维护代码来更新这个值。Ora_rowscn，默认情况下，一个块上多行会共享相同的Ora_rowscn值，如果更新一个块上的某一行，这个块上其他的行的ora_rowscn也会推进。

先看原来的ora_rowscn，下面90253这个块的ora_rowscn都是710757：
SQL> select ln.lnpa_loan_typ, ln.loan_no, dbms_rowid.rowid_block_number(rowid) blockno, ora_rowscn
  2  from loan ln
  3  where rownum < 20;

LNPA_LOAN_TYP LOAN_NO                 BLOCKNO ORA_ROWSCN
------------- -------------------- ---------- ----------
12410         2100004401                90253     710757
12303         2100005901                90253     710757
12502         2100002301                90253     710757
12601         2100003101                90253     710757
11152         2100004301                90253     710757
11376         2100004901                90253     710757
11102         2100003001                90253     710757
12113         2100001001                90253     710757
12112         2100002001                90253     710757
11151         2100004501                90253     710757
11501         2100003403                90254     760733
12230         2100014501                90254     760733
10001         2100001364                90254     760733
12105         2100012401                90254     760733
12042         2100015201                90254     760733
12303         2100011601                90254     760733
11151         2100002901                90254     760733
12410         2100008601                90254     760733
12502         2100003101                90254     760733

19 rows selected

更新90253这个块中一条记录里的值：
SQL> update loan ln
  2  set ln.corr_addr_l1 = ln.corr_addr_l1 || 'new'
  3  where ln.lnpa_loan_typ = '12502' and ln.loan_no = '2100002301';

1 row updated

这个块里的ora_rowscn都变成了1566945，这个新的值是基于目前Oracle相同时针基础上的，也就是说，它的值永远向前推进。
SQL> select ln.lnpa_loan_typ, ln.loan_no, dbms_rowid.rowid_block_number(rowid) blockno, ora_rowscn
  2  from loan ln
  3  where rownum < 20;

LNPA_LOAN_TYP LOAN_NO                 BLOCKNO ORA_ROWSCN
------------- -------------------- ---------- ----------
12410         2100004401                90253    1566945
12303         2100005901                90253    1566945
12502         2100002301                90253    1566945
12601         2100003101                90253    1566945
11152         2100004301                90253    1566945
11376         2100004901                90253    1566945
11102         2100003001                90253    1566945
12113         2100001001                90253    1566945
12112         2100002001                90253    1566945
11151         2100004501                90253    1566945
11501         2100003403                90254     760733
12230         2100014501                90254     760733
10001         2100001364                90254     760733
12105         2100012401                90254     760733
12042         2100015201                90254     760733
12303         2100011601                90254     760733
11151         2100002901                90254     760733
12410         2100008601                90254     760733
12502         2100003101                90254     760733

19 rows selected

上面说到ora_rowscn默认是块级的，如果要使得它是记录级的，就要打开rowdependencies，重新创建表，不能通过修改表来实现。就是在建表语句的字段列表的括号后面加rowdependencies关键字。
大概明白ora_rowscn的原理后，就可以理解怎么通过它来检测行级修改了。
顺便再说一下ora_rowscn，它默认是块级的，如果一条记录字节越少，那块包括的行越多，也就是维护这个块ora_rowscn的消耗就越大。

 
 Copyright ©2011 lyt. All Rights Reserved.






study
oracle死锁

利用多线程可以很好地开发能同时处理多个任务的功能强大的应用程序。值得注意的是，作为多线程程序，程序中的多个线程通常是独立运行的，各个线程有自己的独占资源。但有时对于多个线程来说，某些资源是共享的，在这种情况下，就要考虑其他线程对当前线程的影响。此时，最重要的是要有全局观念，要考虑到与其他共享线程的协调和配合。如果不考虑协调性，就可能会造成系统的严重错误。很多情况下，一个线程必须与其他线程合作才能共同完成任务。 
　　1。线程同步 
　　在java语言中，为保证多个线程对共享资源操作的一致性和完整性，引入了线程的同步机制。所谓线程同步即某个线程在一个完整操作的全执行过程中，独占相关资源而不被侵占。 
　　线程同步的基本思想是协调各线程对共享资源的使用，避免多个线程在某段时间内对同一资源的访问，这个资源可以是数据，代码，设备等。 
　　java通过关键字synchronized来表明被同步的资源，即给资源加个"锁"，这个“锁”我们称之为信号锁。当某个资源被synchronized关键修饰里，系统在运行时都会分配给它的一个信号锁，表明该资源在同一时刻只能由一个线程访问。 
　　但处理线程同步仅仅信号锁是不够的，java专门设计了以下3种方法跟信号锁配合使用： 
　　(1).public final void wait(); 
　　等待方法。该方法是一个最终方法，不能被重载，只能在同步方法中被调用。执行该方法会将当前正在运行的线程挂起，释放所占用的资源，从运行状态转入阻塞状态，进入wait队列等待被唤醒。 
　　(2).public final void notify()； 
　　唤醒方法。该方法是一个最终方法，不能被重载，只能在同步方法中被调用。执行该方法将唤醒wait队列优先级最高的一个线程，占有资源运行。 
　　除了notify()方法外，java还设计了notifyAll方法。它的作用与notify()方法相似，不过它是唤醒wait队列中的所有的线程。 
　　注意：wait(),notify()和notifyAll()这3种方法必须在同步方法中被调用。因此它们只能出现在synchronized作用的范围内。 
　　2.线程死锁 
　　死锁是指两个或多个线程无止境地互相等待的过程，同步不当可能会引发线程的死锁。下述情况可能会死锁：若干线程各自分别占用某资源，又同时需要对方的资源，结果造成相互无限制地等待对方放弃资源，谁也不能执行下去。 
　　为了解决死锁问题，在进行多线程程序设计时需要遵循如下策略： 
　　（1）在指定的任务真正需要并行时，才采用用多线程进行程序设计。 
　　（2）在对象的同步方法中需要调用其他同步方法时必须小心。 
　　（3）对共享资源的占用时间要尽可能的短。
 Copyright ©2011 lyt. All Rights Reserved.





study
数据库事务及并发

当处于高并发环境时，有可能多个事务同时作用于某步操作，这将导致事务在不同时间读取到的数据不一致或修改丢失等错误。
为了避免上述错误， 可采用如下策略：
1.serializable 使用完全隔离的事务,事务看起来像是一个接一个地执行。
2.repeatable 保证每次读取相同的记录能得到相同的结果
3.read commited 通常情况下，我们应该使用该隔离级别， 并结合使用乐观锁和悲观锁。
乐观锁
其原理就是事务在执行更新操作前先判断更新数据是否被修改。可以通过版本号、时间戳、对象状态等来判断是否已被修改。一般情况下，尽量使用版本号来判断，只在对老系统进行升级且无法使用版本号的前提下， 才会使用时间戳。
关于乐观锁，jdbc和ibatis需要用户自己单独实现。jdo和hibernate无需用户单独实现，只需要简单的配置就可以使用。
在如下情况下，不推荐使用乐观锁： 1.数据库模式不支持乐观锁(对老系统进行升级)
2.应用程序必须保证能够更新读取的记录 3.应用程序要求读取的一致性
悲观锁
悲观锁机制会假设更新冲突总会发生。所以不管冲突是否真的会发生，它都会枷锁。悲观锁能在一定程度上防止读取数据的不一致性。但当有insert操作时，读取结果可能不一致。
用法 select ... for update
补充：关于隔离级别，可以通过spring拦截器或jdbc datasource来实现。
通知并发更新
在业务层捕获/处理dao异常并不是一件明智的事，幸运的是，spring提供了一个扩展，能够自动翻译jdbc、hibernate、jdo抛出的数据访问异常。
但是，spring在处理此操作时有一个缺陷，就是spring无法处理由oracle产生的部分错误识别码。如：ORA-00060 ORA-08177等。针对上述情况，我们可以通过扩展 SQLErrorCodeSQLExceptionTranslator来弥补。
使用jdo和hibernate处理并发更新相对比较简单，只需做简单的配置，jdo/hibernate就可自动产生对应的sql语句。
用jdo处理并发更新
<version strategy="version-number" column="XXX"/>
或 <version strategy="timestamp" column="XXX"/>
或 <version strategy="stateimage" column="XXX"/>
hibernate 处理并发更新
使用乐观锁 <version name="version" clumn="XXX"/>
   使用<class>元素的乐观锁属性来定义hibernate采用字段比较来实现乐观锁检查。
   <class dynamic-update="true" optimistic-lock="dirty"...>
   使用悲观锁
   通过调用session.load() session.lock和query.setLockMode()这些方法，锁住对象对应的数据表里的记录。
从数据并发失败中恢复
当并发更新失败，在表示层打印出来不是明智之举。我们应该想办法重新提交事务。一种方式是使用try catch块，不过这种方式将导致业务逻辑代码中含有大量的try catch块。另一种方式是使用Aop interceptor重试事务
注：当应用程序调用了非事务性的api或做了不能恢复的事情(比如发了邮件)，事务就不能自动回滚和恢复。在这些情况下，必须在应用程序级别写代码解决。
 Copyright ©2011 lyt. All Rights Reserved.





study
oracle并发

数据库并发处理    

一、并发处理
数据库的特点就是数据的集中管理和共享。在通常情况下总是有若干个事务并发地运行，这些并行的事务可能并发地存取相同的数据。因此，数据库管理系统的一个重要任务就是要有一种机制去保证这种并发的存取和修改不破坏数据的完整性，确保这些事务能正确地运行并取得正确的结果。
我们知道，事务并发执行时若不加控制的话，将导致不正确的结果和数据库的不一致状态。为保证数据库数据正确地反映所有事务的更新，以及在一事务修改数据时其它事务不同时修改这个数据，数据库系统用锁来控制对数据的并发存取。
二、ORACLE的并发处理机制
无需任何说明，ORACLE自动提供行级锁，它允许用户在没有冲突的情况下更新表中不同的行。行级锁对联机事务处理非常有用。
1、ORACLE锁    
ORACLE锁的类型在正常情况下，ORACLE会自动锁住需要加锁的资源以保护数据，这种锁是隐含的，叫隐含锁。然而，在一些条件下，这些自动的锁在实际应用时并不能满足需要，必须人工加一些锁。这些人工加的锁叫显示锁。
下面指明了会产生隐含锁的SQL语句：  
  INSERT；  
  UPDATE；  
  DELETE；   
  DDL/DCL语句。  
  下面指明了会产生显示锁的SQL语句：  
  SELECT   FOR   UPDATE；  
  LOCK   TABLE   INXXX   MODE。  
解决读的不可重复性可以用下面的方法。在ORACLE中，用SELECT   FOR   UPDATE对预期要修改的记录加行排它锁（X），对表加行共享锁（RS）。它常用于要锁住一行，但不去真的修改这一行。锁之间是有相互作用的。
例如，更新时会对表加RX锁，对行加X锁，而只有RS锁和RX锁允许再加RX锁。因此，当存在RS和RX锁时，表允许更新。再比如，当执行DDL和DCL语句时，会对表加排它锁X，而在存在X、RS、SRX、RX和S锁的前提下，都不能再加X锁。因此，当存在X，RS，SRX，RS或S锁时，不能对表做DCL和DDL操作。这样，数据库会自动防止一个用户更新表中的数据，而其他用户在同时修改表的结构。  
2、ORACLE只读事务    
  ORACLE支持只读事务。只读事务有以下特点：  
  *在事务中只允许查询  
  *其它事务可修改和查询数据  
  *在事务中，其它用户的任何修改都看不见  
  只读事务的写法为：  
  SET   TRANS   ACTION   READONLY  
  SQL语句  
  COMMIT，ROLLBACK，DDL结束只读事务  
3、事务一致性的级别    
事务是定义和维护一致性的单位，封锁就是要保证这种一致性。如果对封锁的要求高会增加开销，降低并发性和效率；有的事务并不严格要求结果的质量（如用于统计的事务），如果加上严格的封锁则是不必要和不经济的。因此有必要进行进一步的分析，考察不同级别的一致性对数据库数据的质量及并行能力的影响。
一致性级别定义为如下的几个条件：  
（1）事务不修改其它任何事务的脏数据。脏数据是被其它事务修改过，但尚未提交的数据。（2）在事务结束前不对被修改的资源解锁。
（3）事务不读其它任何事务的脏数据。
（4）在读前对数据加共享锁（RS）和行排它锁，直至事务结束。  
  *满足条件1的事务叫第0级事务。  
  *满足条件1和2的事务叫第1级一致性事务。  
  *满足条件1、2和3的事务为2级一致性事务。  
ORACLE的读一致性保证了事务不读其它事务的脏数据。  
  *满足条件1、2、3和4的事务叫第3级一致性事务。  
由ORACLE的三个性质：自动加隐式锁、在事务结束时释放锁和读一致性，使ORACLE成为自动满足以上的0、1和2级一致性事务。因此，ORACLE自动防止了脏读（写-读依赖）。但是，ORACLE不能自动防止丢失修改（写-写依赖），读的不可重复性（读-写依赖），彻底解决并发性中的问题还需满足第4个条件（3级一致性事务），这需要程序员根据实际情况编程。  
方法如下：  
    *如果想在一段时间内使一些数据不被其它事务改变，且在本事务内仅仅查询数据，则可用SETTRANSACTIONREADONLY语句达到这一目的。  
    *如果想在一事务内修改一数据，且避免丢失修改，则应在读这一数据前用SELECTFORUPDATE对该数据加锁。  
    *如果想在一事务内读一数据，且想基于这一数据对其它数据修改，则应在读数据前对此数据用SELECTFORUPDATE加锁。对此种类型的应用，用这条SQL语句加锁最恰当。  
    *如果想避免不可重复读现象，可在读前用SELECTFORUPDATE对数据加锁，或用SET   TRANS   ACTION   READONLY设置只读事务。  
问题背景及特点：

    我们在使用多用户数据库时常常会碰到数据更新失败、删除失等情况，如果有多个用户且同时访问一个数据库则当他们的事务同时使用相同的数据时可能会发生并发问题。
    并发问题包括：
    1.丢失或覆盖更新。(幻像读)
    2.未确认的相关性（脏读）。
    3.不一致的分析（非重复读）。
详细描述：
1.丢失更新
 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，会发生丢失更新问题。每个事务都不知道其它事务的存在。最后的更新将重写由其它事务所做的更新，这将导致数据丢失。
    例如，两个编辑人员制作了同一文档的电子复本。每个编辑人员独立地更改其复本，然后保存更改后的复本，这样就覆盖了原始文档。最后保存其更改复本的编辑人员覆盖了第一个编辑人员所做的更改。如果在第一个编辑人员完成之后第二个编辑人员才能进行更改，则可以避免该问题。
2.未确认的相关性（脏读）
当第二个事务选择其它事务正在更新的行时，会发生未确认的相关性问题。第二个事务正在读取的数据还没有确认并且可能由更新此行的事务所更改。
    例如，一个编辑人员正在更改电子文档。在更改过程中，另一个编辑人员复制了该文档（该复本包含到目前为止所做的全部更改）并将其分发给预期的用户。此后，第一个编辑人员认为目前所做的更改是错误的，于是删除了所做的编辑并保存了文档。分发给用户的文档包含不再存在的编辑内容，并且这些编辑内容应认为从未存在过。如果在第一个编辑人员确定最终更改前任何人都不能读取更改的文档，则可以避免该问题。
3.不一致的分析（非重复读）
当第二个事务多次访问同一行而且每次读取不同的数据时，会发生不一致的分析问题。不一致的分析与未确认的相关性类似，因为其它事务也是正在更改第二个事务正在读取的数据。然而，在不一致的分析中，第二个事务读取的数据是由已进行了更改的事务提交的。而且，不一致的分析涉及多次（两次或更多）读取同一行，而且每次信息都由其它事务更改；因而该行被非重复读取。
    例如，一个编辑人员两次读取同一文档，但在两次读取之间，作者重写了该文档。当编辑人员第二次读取文档时，文档已更改。原始读取不可重复。如果只有在作者全部完成编写后编辑人员才可以读取文档，则可以避免该问题。
4.幻像读
当对某行执行插入或删除操作，而该行属于某个事务正在读取的行的范围时，会发生幻像读问题。事务第一次读的行范围显示出其中一行已不复存在于第二次读或后续读中，因为该行已被其它事务删除。同样，由于其它事务的插入操作，事务的第二次或后续读显示有一行已不存在于原始读中。
例如，一个编辑人员更改作者提交的文档，但当生产部门将其更改内容合并到该文档的主复本时，发现作者已将未编辑的新材料添加到该文档中。如果在编辑人员和生产部门完成对原始文档的处理之前，任何人都不能将新材料添加到文档中，则可以避免该问题。
从上面可以看到，解决并发主要是用到了锁和事务。
锁  ：给记录或表加上锁是为了对当前操作对象加上一个状态表示位，让其它用户在获取编辑权限时有了判断。
事务：是为了保证一组操作的完整性。(要么就全部成功，要么就全部失败)
一般处理并发问题时我这样做：
1.开启事务。
2.申请写权限，也就是给对象(表或记录)加锁。
3.如果失败，则结束事务，过一会重试。
4.如果成功，也就是给对象加锁成功，防止其它用户再用同样的方式打开。
5.进行编辑操作。
6.写入所进行的编辑结果。
7.如果写入成功，则提交事务,完成操作。
8.如果写入失败，则回滚事务，取消提交。
9.(7.8)两步操作已释放了锁定的对象，恢复到操作前的状态。
Oracle与SQL Server事务处理的比较

事务处理是所有大型数据库产品的一个关键问题，各数据库厂商都在这个方面花费了很大精力，不同的事务处理方式会导致数据库性能和功能上的巨大差异。事务处理也是数据库管理员与数据库应用程序开发人员必须深刻理解的一个问题，对这个问题的疏忽可能会导致应用程序逻辑错误以及效率低下。
下面我们针对Oracle及SQL Server这两种当前广泛使用的大型数据库产品，探讨一下它们在事务处理方面的一些差异。如没有特殊说明，本文内容适用的数据库产品版本为Oracle9i及SQL Server 2000，其中的示例SQL语句，对于Oracle是在SQL*Plus中执行，而对于SQL Server 2000是在osql中执行。
1. 事务的概念
     事务可以看作是由对数据库的若干操作组成的一个单元，这些操作要么都完成，要么都取消，从而保证数据满足一致性的要求。事务的一个典型例子是银行中的转帐操作，帐户A把一定数量的款项转到帐户B上，这个操作包括两个步骤，一个是从帐户A上把存款减去一定数量，二是在帐户B上把存款加上相同的数量。这两个步骤显然要么都完成，要么都取消，否则银行就会受损失。显然，这个转帐操作中的两个步骤就构成一个事务。
数据库中的事务还有如下ACID特征。
     ACID分别是四个英文单词的首写字母，这四个英文单词是Atomicity、Consistency、Isolation、Durability，分别翻译为原子性、一致性、隔离性、持久性。
    原子性：指事务中的操作，或者都完成，或者都取消。
    一致性：指事务中的操作保证数据库中的数据不会出现逻辑上不一致的情况，一致性一般会隐含的包括在其他属性之中。
    隔离性：指当前的事务与其他未完成的事务是隔离的。在不同的隔离级别下，事务的读取操作，可以得到的结果是不同的。
    持久性：指对事务发出COMMIT命令后，即使这时发生系统故障，事务的效果也被持久化了。与此相反的是，当在事务执行过程中，系统发生故障，则事务的操作都被回滚，即数据库回到事务开始之前的状态。
    对数据库中的数据修改都是在内存中完成的，这些修改的结果可能已经写到硬盘也可能没有写到硬盘，如果在操作过程中，发生断电或系统错误等故障，数据库可以保证未结束的事务对数据库的数据修改结果即使已经写入磁盘，在下次数据库启动后也会被全部撤销；而对于结束的事务，即使其修改的结果还未写入磁盘，在数据库下次启动后会通过事务日志中的记录进行“重做”，即把丢失的数据修改结果重新生成，并写入磁盘，从而保证结束事务对数据修改的永久化。这样也保证了事务中的操作要么全部完成，要么全部撤销。
2. 事务设置及类型的区别
    在SQL Server中有三种事务类型，分别是：隐式事务、显式事务、自动提交事务，缺省为自动提交。
    自动提交，是指对于用户发出的每条SQL语句，SQL Server都会自动开始一个事务，并且在执行后自动进行提交操作来完成这个事务，也可以说在这种事务模式下，一个SQL语句就是一个事务。
    显式事务，是指在自动提交模式下以Begin Transaction开始一个事务，以Commit或Rollback结束一个事务，以Commit结束事务是把事务中的修改永久化，即使这时发生断电这样的故障。例如下面是SQL Server中的一个显式事务的例子。
Begin Tran
Update emp Set ename=’Smith’ Where empno=7369
Insert Into dept Values(60,’HR’,’GZh’)
Commit
    隐式事务，是指在当前会话中用Set Implicit_Transactions On命令设置的事务类型，这时任何DML语句(Delete、Update、Insert)都会开始一个事务，而事务的结束也是用Commit或Rollback。
    在Oracle中没有SQL Server的这些事务类型，缺省情况下任何一个DML语句都会开始一个事务，直到用户发出Commit或Rollback操作，这个事务才会结束，这与SQL Server的隐式事务模式相似。
3. 事务隔离级别
    在SQL92标准中，事务隔离级别分为四种，分别为：Read Uncommitted、Read Committed、Read Repeatable、Serializable，其中Read Uncommitted与Read Committed为语句级别的，而Read Repeatable与Serializable是针对事务级别的。
    在Oracle和SQL Server中设置事务隔离级别的语句是相同的，都使用SQL92标准语法，即：
Set Transaction Isolation Level Read Committed
    上面示例中的Read Committed可以被替换为其他三种隔离级别中的任意一种。
1) SQL Server中的隔离级别及实现机制
    在SQL Server中提供了所有这四种隔离级别。
    下面我们讨论在SQL Server中，这几种隔离级别的含义及其实现方式。
    Read Uncommitted：一个会话可以读取其他事务未提交的更新结果，如果这个事务最后以回滚结束，这时的读取结果就可能是错误的，所以多数的数据库应用都不会使用这种隔离级别。
    Read Committed：这是SQL Server的缺省隔离级别，设置为这种隔离级别的事务只能读取其他事务已经提交的更新结果，否则，发生等待，但是其他会话可以修改这个事务中被读取的记录，而不必等待事务结束，显然，在这种隔离级别下，一个事务中的两个相同的读取操作，其结果可能不同。
    Read Repeatable：在一个事务中，如果在两次相同条件的读取操作之间没有添加记录的操作，也没有其他更新操作导致在这个查询条件下记录数增多，则两次读取结果相同。换句话说，就是在一个事务中第一次读取的记录保证不会在这个事务期间发生改变。SQL Server是通过在整个事务期间给读取的记录加锁实现这种隔离级别的，这样，在这个事务结束前，其他会话不能修改事务中读取的记录，而只能等待事务结束，但是SQL Server不会阻碍其他会话向表中添加记录，也不阻碍其他会话修改其他记录。
    Serializable：在一个事务中，读取操作的结果是在这个事务开始之前其他事务就已经提交的记录，SQL Server通过在整个事务期间给表加锁实现这种隔离级别。在这种隔离级别下，对这个表的所有DML操作都是不允许的，即要等待事务结束，这样就保证了在一个事务中的两次读取操作的结果肯定是相同的。
2) Oracle中的隔离级别及实现机制
    在Oracle中，没有Read Uncommitted及Repeatable Read隔离级别，这样在Oracle中不允许一个会话读取其他事务未提交的数据修改结果，从而避免了由于事务回滚发生的读取错误。Oracle中的Read Committed和Serializable级别，其含义与SQL Server类似，但是实现方式却大不一样。
    在Oracle中，存在所谓的回滚段(Oracle9i之前版本)或撤销段(Oracle9i版本)，Oracle在修改数据记录时，会把这些记录被修改之前的结果存入回滚段或撤销段中，就是因为这种机制，Oracle对于事务隔离级别的实现与SQL Server截然不同。在Oracle中，读取操作不会阻碍更新操作，更新操作也不会阻碍读取操作，这样在Oracle中的各种隔离级别下，读取操作都不会等待更新事务结束，更新操作也不会因为另一个事务中的读取操作而发生等待，这也是Oracle事务处理的一个优势所在。
    Oracle缺省的设置是Read Committed隔离级别(也称为语句级别的隔离)，在这种隔离级别下，如果一个事务正在对某个表进行DML操作，而这时另外一个会话对这个表的记录进行读取操作，则Oracle会去读取回滚段或撤销段中存放的更新之前的记录，而不会象SQL Server一样等待更新事务的结束。
    在Serializable隔离级别(也称为事务级别的隔离)，事务中的读取操作只能读取这个事务开始之前已经提交的数据结果。如果在读取时，其他事务正在对记录进行修改，则Oracle就会在回滚段或撤销段中去寻找对应的原来未经更改的记录(而且是在读取操作所在的事务开始之前存放于回滚段或撤销段的记录)，这时读取操作也不会因为相应记录被更新而等待。
4. DDL语句对事务的影响
1) Oracle中DDL语句对事务的影响
    在Oracle中，执行DDL语句(如Create Table、Create View等)时，会在执行之前自动发出一个Commit命令，并在随后发出一个Commit或者Rollback命令，也就是说，DDL会象如下伪码一样执行：
Commit;
DDL_Statement;
If (Error) then
Rollback;
Else
Commit;
End if;

我们通过分析下面例子来看Oracle中，DDL语句对事务的影响：
Insert into some_table values(‘Before’);
Creaate table T(x int);
Insert into some_table values(‘After’);
Rollback;
    由于在Oracle执行Create table语句之前进行了提交，而在Create table执行后也会自动发出Commit命令，所以只有插入After的行被回滚，而插入Before的行不会被回滚，Create table命令的结果也不会被回滚，即使Create table语句失败，所进行的Before插入也会被提交。如果最后发出Commit命令，因为插入Before及Create table的操作结果已经在之前提交，所以Commit命令影响的只有插入After的操作。
2) SQL Server中DDL语句对事务的影响
在SQL Server中，DDL语句对事务的影响与其他DML语句相同，也就是说，在DML语句发出之前或之后，都不会自动发出Commit命令。
在SQL Server 2000中，对于与上面Oracle同样的例子，最后发出Rollback后，数据库会回滚到插入Before之前的状态，即插入Before和After的行都会被回滚，数据表T也不会被创建。
如果最后发出Commit操作，则会把三个操作的结果全部提交。
5. 用户断开数据库连接对事务的影响
    另外，对应于Oracle的管理客户端工具SQL*Plus，在SQL Server 2000中是osql，两种管理工具都是命令行工具，使用方式及作用也类似，但是在SQL*Plus中，用户退出连接时，会自动先发出Commit命令，然后再退出，而在osql中，如果用户退出连接，会自动发出Rollback命令，这对于SQL Server的自动提交模式没有什么影响，但如果处于隐式事务模式，其影响是显而易见的。对于两种数据库产品的其他客户端管理工具也有类似的不同之处
 
 Copyright ©2011 lyt. All Rights Reserved.







study
数据库的并发

 
 数据库的并发
并发与恢复一样，与底层系统是关系型还是其它类型无关。
DBMS 允许多个事务同时访问数据库，这即是并发。首先考虑任何一个并发机制必须提及的一些问题是，在三种情况下必定将发生错误。这三种情况是，丢失更新问题、依 赖未提交问题和不一致分析问题。即在这三种情况下，一个事务即使自身是正确的，如果其他的某个事务以某种方式与之交错运行，也可能引发错误。解决并发问题 可以采用锁机制，但是有时锁机制会出现死锁问题。死锁发生时，系统必须能检测并解除它。对死锁问题，有些系统采用的是检测死锁，即是检测等待图中的环；有 些系统采用的是超时机制，假设在预定时间内不工作的事务发生了死锁。解除死锁就是选出一个死锁事务，即图中环上的一个事务，将之回滚，从而释放其所拥有的 锁使得其他的一些事务可继续执行下去。
死锁，发生于两个或更多事务同时处于等待状态，每个事务都在等待其它事务释放锁，可使其继续进行。理论上死锁可涉及到三、四个或更多事务，但是SYSTEM R实验表明，实际上死锁几乎从未涉及到两个以上的事务。
锁，分为排它锁exclusive lock ,也称为X锁、写锁；共享锁shared lock，也称为S锁、读锁。基本思想是，当一个事务需要确保其感兴趣的对象，通常是一数据库元组，在其完成时不会发生某种形式的改变，它必须获得该对象 上的一个锁。锁的作用就是锁住对象使得其它事务无法访问，尤其是阻止其他事务改变该对象。
数据存取协议或称为锁协议，其运用X锁和S锁保证了上面提到的并发问题不会发生。１．事务在检索元组前需要获得该元组上的S锁。２．事务
在更新元组前需要获得该元组上的X锁。相应地，如果其已经具有了该元组上的 S 锁，因为通常是RETRIEVE—UPDATE的顺序，必须将其从S锁升级到X锁。注意，事务对元组的锁请求通常都是隐式的，‘检索’元组的请求通常隐含 着对相关元组的S锁请求，‘更新’元组的请求通常隐含着对相关元组的X锁请求。当然，术语‘更新’包括INSERT\DELETE\UPDATE，但是对 INSERT和DELETE操作，规则需进一步的提炼，这里略去了细节。
３．如果事务B的锁请求因为与事务A已具有的锁冲突而被拒绝，事务B处于等待状态，直到A的锁被释放掉。注意，系统必须保证B不会永远处于等待状态，这是可能的，通常称为活锁。避免活锁的简单方法是采用先来先服务的策略。
４．X锁将一直保持直到事务结束，COMMIT或ROLLBACK。
小结
本部分考虑了有关并发控制的问题。首先介绍了并发事务的交替执行中没有并发控制时会产生的三个问题，即：丢失更新、未提交依赖和不一致分析。产生这些问题的调度都不是可以串行化的，即不能等价于涉及相同事务的某个串行调度。
解决这些问题的最广泛的技术是锁。锁的基本类型有两种，即共享锁（S 锁）和排它锁（X锁）。如果某个事务在某个对象上施加了S锁，则其他事务也能在该对象上申请S锁，但不能对该对象申请X锁；如果某个事务在某个对象上施加 了X锁，则其他事务不能对该对象申请如何锁。为了保证不发生丢失修改，可以引入这样一个锁协议：对任何要检索的对象申请S锁，对任何要更新的对象申请X 锁，并将锁保持到事务结束。该协议可以实现事务的串行化。
上面所描述的协议是两段锁协议的一个较强但很常见的形式。由此得出两段锁定理：如果所有的事务都遵循该协议，那么所有的调度都是可串行的。可串行调度意味着：如果A和B是该调度所涉及的两个事务，那么或者A看到B的输出，或者B看到A的输出。遗憾的是，两段锁协议可能导致死锁的发生。打破死锁的办法是选择死锁事务中的某一个事务作为牺牲者（v i c t i m），然后将该事务回滚（从而释放牺牲者所锁定的全部资源）。
一般说来，如果事务未达到完全可串行性，则不能保证一定安全。但系统一般都允许事务在某个实际上并不安全的隔离级别上运行，这样可以减少资源的竞争并提高事务吞吐量。
接下来主要说明锁粒度的问题及相应的意向锁思想。意向锁的基本观点是：事务在某些对象（如数据库中的元组）上获得某种锁前，它必须先获得在该对象的“父对象”上的一个适当的意向锁。例如，对于一个元组则要在包含该元组的关系变量上获得一个意向锁。这样的意向锁通常以隐式申请方式实现，就像元组上的S锁和X锁以隐式方式申请一样。但是也应该提供某些意向锁的显式锁语句以允许事务在必要时能够获得较隐式方式获得的锁。
最后给出了S Q L对并发控制支持的几个要点。S Q L基本上不提供任何的显式锁能力，但它支持多种隔离级别，即：读未提交、读已提交、可重复读和可串行化的等四种。这些不同的隔离级别可以由D B M S通过非显式锁方式加以实现。 在连接数据库后可以设置操作的隔离级别。
对于完整性的重要性问题，这里进一步给出一个简要的说明。在较泛泛地讲数据库正确时，一般指数据库没有违背任何已知的完整性约束。因此容易看出，对于未提供较多完整性支持的系统而言，它只能提供较弱意义上的数据库“正确”。在第1 4章中提到的恢复指的是恢复到以前的某个已知的“正确状态”，而本章中的并发（或者说并发控制）则指的是一个可串行调
度将把数据库从一个“正确状态”转移 到另一个“正确状态”。由此可见，完整性是比恢复和并发更为基本的问题。事实上，完整性是单用户系统中也要考虑的问题。
 Copyright ©2011 lyt. All Rights Reserved.








 